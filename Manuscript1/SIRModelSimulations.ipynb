{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Importing the required packages\n",
    "import igraph as ig\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "# Specifying the figure parameters\n",
    "font = {'family': 'serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 18,\n",
    "        }\n",
    "params = {'legend.fontsize': 16,\n",
    "          'legend.handlelength': 2.}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Required functions for the SIR Simulation\n",
    "\n",
    "def max_connect(g,m):\n",
    "    \"\"\"randomly removes edges for nodes that have more than m connections\"\"\"\n",
    "    no_edge_rm = 0\n",
    "    for n in g.vs:\n",
    "        if n.degree() > m:\n",
    "            nlist = g.neighbors(n)\n",
    "            nremove = n.degree()-m\n",
    "            nlistremove = rd.sample(nlist, k=nremove)\n",
    "            no_edge_rm = no_edge_rm + nremove\n",
    "            for i in nlistremove:\n",
    "                g.delete_edges(g.es[g.get_eid(i, n)])\n",
    "    return no_edge_rm\n",
    "\n",
    "def remove_edg(g,m):\n",
    "    \"\"\"randomly removes m edges from a network g\"\"\"\n",
    "    edg_rm = rd.sample(range(len(g.es)), k=m)\n",
    "    g.delete_edges(edg_rm)\n",
    "\n",
    "def results(fname,iters=100,pop=10000,setseed=3,edge_per_node=2,infect_len=5,days=170,\n",
    "            mitigation=False,m=8,probs_inf=[0.01,0.01,0.1,0.2,0.3,0.3,0.3,0.25,0.2,0.15,0.1,0.05,0.01,0.01],\n",
    "            mitigation2=False,m2=100):\n",
    "    \"\"\"stores the results of the SIR model for stats/plotting\"\"\"\n",
    "    time_1perc_all = [] #time when 1% of the population is infected\n",
    "    tot_time_1perc_all = [] #total time for which 1% of the population is infected\n",
    "    time_1hub_all = [] #time when the first hub is infected\n",
    "    cl_coeffs_all = [] #clustering coefficient of network at each iteration\n",
    "    S_final = []\n",
    "    R_final = []\n",
    "    I_final = []\n",
    "    no_rm_all = []\n",
    "    peak_time_all = []\n",
    "    peak_perc_all = []\n",
    "    for i in range(0,iters):\n",
    "        time_1perc = False\n",
    "        time_1hub = False\n",
    "        tt = False\n",
    "        tt_peak = False\n",
    "        tot_time_1perc = 0.0\n",
    "        I_stores = 0.0\n",
    "        setseed = setseed+1\n",
    "        g = ig.Graph.Barabasi(pop, edge_per_node,power=1)\n",
    "        if mitigation is True:\n",
    "            no_rm = max_connect(g,m) # limits the maximum number of neighbors to m\n",
    "            no_rm_all.append(no_rm)\n",
    "        if mitigation2 is True:\n",
    "            remove_edg(g,m2) # randomly removes m2 edges from the network\n",
    "        g.vs[\"state\"] = \"S\"\n",
    "        g.vs[\"duration\"] = 0\n",
    "        i = rd.randint(0, pop-1)\n",
    "        g.vs[i][\"state\"] = \"I\"\n",
    "        for time in range(days): #no. of days\n",
    "            if len(g.vs.select(state_eq = \"I\")) > pop*0.01 and time_1perc is False:\n",
    "                #stores the time that 1% of the population is infected\n",
    "                time_1perc = True\n",
    "                tot_time_1perc = float(time)\n",
    "                time_1perc_all.append(time)\n",
    "            if len(g.vs.select(state_eq = \"I\")) < pop*0.01 and tot_time_1perc > 0.0 and tt is False:\n",
    "                #stores the total time for which 1% of the population is infected\n",
    "                tot_time = time - tot_time_1perc\n",
    "                tot_time_1perc_all.append(tot_time)\n",
    "                tt = True\n",
    "                # stores the clustering coefficient associated with that time\n",
    "                cl_coeff = g.transitivity_undirected()\n",
    "                cl_coeffs_all.append(cl_coeff)\n",
    "            for n in g.vs.select(state_eq = \"I\"): #iterates through each node in the network\n",
    "                if g.vs[n.index][\"duration\"] is 0 and len(g.neighbors(n)) > m and time_1hub is False:\n",
    "                    #stores the time that the first hub is infected\n",
    "                    time_1hub = True\n",
    "                    time_1hub_all.append(time)\n",
    "                g.vs[n.index][\"duration\"] += 1 #from day 0 to infect_len this node continues to infect\n",
    "                day_inf = g.vs[n.index][\"duration\"]\n",
    "                for nb in g.neighbors(n): #iterates through neighbours of that node\n",
    "                    if g.vs[nb][\"state\"] == \"S\": #if node is infected...\n",
    "                        r = rd.random() #random state\n",
    "                        if r < probs_inf[day_inf]:\n",
    "                            g.vs[nb][\"state\"] = \"I\" #change state to infected\n",
    "                if g.vs[n.index][\"duration\"] >= rd.randrange(2,14): #after infect_len that node changes to recovered\n",
    "                    g.vs[n.index][\"state\"] = \"R\"\n",
    "            if time == days-1:\n",
    "                S_final.append(len(g.vs.select(state_eq = \"S\")))\n",
    "                I_final.append(len(g.vs.select(state_eq = \"I\")))\n",
    "                R_final.append(len(g.vs.select(state_eq = \"R\")))\n",
    "            if time_1perc is True and I_stores > len(g.vs.select(state_eq = \"I\")) and tt_peak is False:\n",
    "                # if pop greater than 1% and previous no. of infected nodes is higher than current assume peak\n",
    "                tt_peak = True\n",
    "                peak_time_all.append(time)\n",
    "                peak_perc_all.append(I_stores)\n",
    "            I_stores = len(g.vs.select(state_eq = \"I\"))\n",
    "    if sum(I_final) > 0:\n",
    "        print(\"Model not run long enough!\")\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump([peak_time_all, peak_perc_all, cl_coeffs_all, tot_time_1perc_all, time_1perc_all, time_1hub_all, S_final, I_final, R_final], f)\n",
    "    return no_rm_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Storing the variables as pickle files\n",
    "\n",
    "# Scale-Free\n",
    "for i in range(50,51):\n",
    "    no_rm_all = results('SIR{}.pickle'.format(i),iters=100,setseed=i*1000)\n",
    "\n",
    "# Mitigation Hubs\n",
    "avg_rm = []\n",
    "for i in range(50,51):\n",
    "    no_rm_all = results('SIR{}_M.pickle'.format(i),iters=100,setseed=i*1000,mitigation=True,m=8)\n",
    "    avg_rm = avg_rm + no_rm_all\n",
    "\n",
    "# Mitigation Random\n",
    "for i in range(50,51):\n",
    "    no_rm_all = results('SIR{}_M2.pickle'.format(i),iters=100,setseed=i*1000,mitigation2=True,m2=int(np.mean(avg_rm)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}